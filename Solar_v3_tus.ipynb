{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1748453873195
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(20000, 17) (12000, 16)\n",
            "Index(['id', 'temperature', 'irradiance', 'humidity', 'panel_age',\n",
            "       'maintenance_count', 'soiling_ratio', 'voltage', 'current',\n",
            "       'module_temperature', 'cloud_coverage', 'wind_speed', 'pressure',\n",
            "       'string_id', 'error_code', 'installation_type', 'efficiency'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "#sample_submission = pd.read_csv('sample_submission.csv')\n",
        "\n",
        "# üìä Check data\n",
        "print(train.shape, test.shape)\n",
        "print(train.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>temperature</th>\n",
              "      <th>irradiance</th>\n",
              "      <th>humidity</th>\n",
              "      <th>panel_age</th>\n",
              "      <th>maintenance_count</th>\n",
              "      <th>soiling_ratio</th>\n",
              "      <th>voltage</th>\n",
              "      <th>current</th>\n",
              "      <th>module_temperature</th>\n",
              "      <th>cloud_coverage</th>\n",
              "      <th>wind_speed</th>\n",
              "      <th>pressure</th>\n",
              "      <th>string_id</th>\n",
              "      <th>error_code</th>\n",
              "      <th>installation_type</th>\n",
              "      <th>efficiency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>7.817315</td>\n",
              "      <td>576.179270</td>\n",
              "      <td>41.24308670850264</td>\n",
              "      <td>32.135501</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.803199</td>\n",
              "      <td>37.403527</td>\n",
              "      <td>1.963787</td>\n",
              "      <td>13.691147</td>\n",
              "      <td>62.494044</td>\n",
              "      <td>12.82491203459621</td>\n",
              "      <td>1018.8665053152533</td>\n",
              "      <td>A1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.562096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>24.785727</td>\n",
              "      <td>240.003973</td>\n",
              "      <td>1.3596482765960705</td>\n",
              "      <td>19.977460</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.479456</td>\n",
              "      <td>21.843315</td>\n",
              "      <td>0.241473</td>\n",
              "      <td>27.545096</td>\n",
              "      <td>43.851238</td>\n",
              "      <td>12.012043660984917</td>\n",
              "      <td>1025.6238537572883</td>\n",
              "      <td>D4</td>\n",
              "      <td>E00</td>\n",
              "      <td>dual-axis</td>\n",
              "      <td>0.396447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>46.652695</td>\n",
              "      <td>687.612799</td>\n",
              "      <td>91.26536837560256</td>\n",
              "      <td>1.496401</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.822398</td>\n",
              "      <td>48.222882</td>\n",
              "      <td>4.191800</td>\n",
              "      <td>43.363708</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.814399755560454</td>\n",
              "      <td>1010.9226539809573</td>\n",
              "      <td>C3</td>\n",
              "      <td>E00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.573776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>53.339567</td>\n",
              "      <td>735.141179</td>\n",
              "      <td>96.19095521176159</td>\n",
              "      <td>18.491582</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.837529</td>\n",
              "      <td>46.295748</td>\n",
              "      <td>0.960567</td>\n",
              "      <td>57.720436</td>\n",
              "      <td>67.361473</td>\n",
              "      <td>8.736258932034128</td>\n",
              "      <td>1021.8466633134253</td>\n",
              "      <td>A1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>dual-axis</td>\n",
              "      <td>0.629009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5.575374</td>\n",
              "      <td>12.241203</td>\n",
              "      <td>27.495073003585226</td>\n",
              "      <td>30.722697</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.551833</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.898062</td>\n",
              "      <td>6.786263</td>\n",
              "      <td>3.632000</td>\n",
              "      <td>0.52268384077164</td>\n",
              "      <td>1008.5559577591927</td>\n",
              "      <td>B2</td>\n",
              "      <td>E00</td>\n",
              "      <td>fixed</td>\n",
              "      <td>0.341874</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  temperature  irradiance            humidity  panel_age  \\\n",
              "0   0     7.817315  576.179270   41.24308670850264  32.135501   \n",
              "1   1    24.785727  240.003973  1.3596482765960705  19.977460   \n",
              "2   2    46.652695  687.612799   91.26536837560256   1.496401   \n",
              "3   3    53.339567  735.141179   96.19095521176159  18.491582   \n",
              "4   4     5.575374   12.241203  27.495073003585226  30.722697   \n",
              "\n",
              "   maintenance_count  soiling_ratio    voltage   current  module_temperature  \\\n",
              "0                4.0       0.803199  37.403527  1.963787           13.691147   \n",
              "1                8.0       0.479456  21.843315  0.241473           27.545096   \n",
              "2                4.0       0.822398  48.222882  4.191800           43.363708   \n",
              "3                3.0       0.837529  46.295748  0.960567           57.720436   \n",
              "4                6.0       0.551833   0.000000  0.898062            6.786263   \n",
              "\n",
              "   cloud_coverage          wind_speed            pressure string_id  \\\n",
              "0       62.494044   12.82491203459621  1018.8665053152533        A1   \n",
              "1       43.851238  12.012043660984917  1025.6238537572883        D4   \n",
              "2             NaN   1.814399755560454  1010.9226539809573        C3   \n",
              "3       67.361473   8.736258932034128  1021.8466633134253        A1   \n",
              "4        3.632000    0.52268384077164  1008.5559577591927        B2   \n",
              "\n",
              "  error_code installation_type  efficiency  \n",
              "0        NaN               NaN    0.562096  \n",
              "1        E00         dual-axis    0.396447  \n",
              "2        E00               NaN    0.573776  \n",
              "3        NaN         dual-axis    0.629009  \n",
              "4        E00             fixed    0.341874  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1748453882481
        }
      },
      "outputs": [],
      "source": [
        "# üßπ Preprocessing - Handle categorical variables\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "cat_cols = ['string_id', 'error_code', 'installation_type']\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    train[col] = le.fit_transform(train[col])\n",
        "    test[col] = le.fit_transform(test[col])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def target_encode(train, test, column, target):\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    global_mean = train[target].mean()\n",
        "    train_encoded = pd.Series(index=train.index, dtype=float)\n",
        "\n",
        "    for train_idx, val_idx in kf.split(train):\n",
        "        fold_train, fold_val = train.iloc[train_idx], train.iloc[val_idx]\n",
        "        means = fold_train.groupby(column)[target].mean()\n",
        "        train_encoded.iloc[val_idx] = fold_val[column].map(means).fillna(global_mean)\n",
        "\n",
        "    test_encoded = test[column].map(train.groupby(column)[target].mean()).fillna(global_mean)\n",
        "    \n",
        "    return train_encoded, test_encoded\n",
        "\n",
        "for col in ['string_id', 'error_code', 'installation_type']:\n",
        "    train[col + '_te'], test[col + '_te'] = target_encode(train, test, col, 'efficiency')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1748453958808
        }
      },
      "outputs": [],
      "source": [
        "# ‚úÖ Convert numeric columns to float (fix for multiplication error)\n",
        "numeric_cols = [\n",
        "    'temperature', 'irradiance', 'humidity', 'panel_age', 'maintenance_count',\n",
        "    'soiling_ratio', 'voltage', 'current', 'module_temperature', 'cloud_coverage',\n",
        "    'wind_speed', 'pressure'\n",
        "]\n",
        "\n",
        "for col in numeric_cols:\n",
        "    train[col] = pd.to_numeric(train[col], errors='coerce')\n",
        "    test[col] = pd.to_numeric(test[col], errors='coerce')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.experimental import enable_iterative_imputer # noqa\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "def impute_data(df):\n",
        "    df = df.copy()\n",
        "    # Handle missing values using Iterative Imputer\n",
        "    #if 'target' in df.columns:\n",
        "    if 'efficiency' in df.columns:\n",
        "        df = df.drop(columns=['efficiency'])  # Drop target column for imputation\n",
        "        \n",
        "    imputer = IterativeImputer(max_iter=10, random_state=42)\n",
        "    df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
        "    return df_imputed\n",
        "\n",
        "train = impute_data(train)\n",
        "test = impute_data(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['id', 'temperature', 'irradiance', 'humidity', 'panel_age',\n",
              "       'maintenance_count', 'soiling_ratio', 'voltage', 'current',\n",
              "       'module_temperature', 'cloud_coverage', 'wind_speed', 'pressure',\n",
              "       'string_id', 'error_code', 'installation_type', 'string_id_te',\n",
              "       'error_code_te', 'installation_type_te'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.columns\n",
        "test.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\tusha\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "C:\\Users\\tusha\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "C:\\Users\\tusha\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "C:\\Users\\tusha\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "# add new feature \n",
        "train['irradiance_squared'] = train['irradiance'] ** 2\n",
        "test['irradiance_squared'] = test['irradiance'] ** 2\n",
        "\n",
        "train['temperature_squared'] = train['temperature'] ** 2\n",
        "test['temperature_squared'] = test['temperature'] ** 2\n",
        "\n",
        "train['Power'] = train['voltage'] * train['current']\n",
        "test['Power'] = test['voltage'] * test['current']\n",
        "\n",
        "train['efficiency_ratio'] = train['Power'] / train['irradiance']\n",
        "test['efficiency_ratio'] = test['Power'] / test['irradiance']\n",
        "\n",
        "train['weather_impact'] = train['cloud_coverage'] * train['wind_speed'] / train['pressure']\n",
        "test['weather_impact'] = test['cloud_coverage'] * test['wind_speed'] / test['pressure']\n",
        "\n",
        "train['maintenance_effectiveness'] = train['maintenance_count'] / (train['panel_age'] * train['soiling_ratio'])\n",
        "test['maintenance_effectiveness'] = test['maintenance_count'] / (test['panel_age'] * test['soiling_ratio'])\n",
        "\n",
        "train['error_severity'] = train['error_code'] * train['string_id']\n",
        "test['error_severity'] = test['error_code'] * test['string_id']\n",
        "\n",
        "\n",
        "train['energy_efficiency'] = train['Power'] / (train['irradiance'] * train['panel_age'])\n",
        "test['energy_efficiency'] = test['Power'] / (test['irradiance'] * test['panel_age'])\n",
        "\n",
        "train['maintenance_score'] = train['maintenance_count'] / (train['panel_age'] + 1)\n",
        "test['maintenance_score'] = test['maintenance_count'] / (test['panel_age'] + 1)\n",
        "\n",
        "train['error_impact'] = train['error_code'] * train['string_id'] / (train['panel_age'] + 1)\n",
        "test['error_impact'] = test['error_code'] * test['string_id'] / (test['panel_age'] + 1)\n",
        "\n",
        "\n",
        "#### remove if acc falls\n",
        "train['log_irradiance'] = np.log1p(train['irradiance'])\n",
        "test['log_irradiance'] = np.log1p(test['irradiance'])\n",
        "\n",
        "train['log_temperature'] = np.log1p(train['temperature'])\n",
        "test['log_temperature'] = np.log1p(test['temperature'])\n",
        "\n",
        "train['log_power'] = np.log1p(train['Power'])\n",
        "test['log_power'] = np.log1p(test['Power'])\n",
        "\n",
        "train['output_efficiency'] = train['efficiency_ratio'] * train['weather_impact']\n",
        "test['output_efficiency'] = test['efficiency_ratio'] * test['weather_impact']\n",
        "\n",
        "train['grid_stability'] = train['voltage'] * train['current'] / (train['panel_age'] + 1)\n",
        "test['grid_stability'] = test['voltage'] * test['current'] / (test['panel_age'] + 1)\n",
        "\n",
        "\n",
        "train['panel_health_index'] = train['Power'] / (train['panel_age'] * train['soiling_ratio'])\n",
        "test['panel_health_index'] = test['Power'] / (test['panel_age'] * test['soiling_ratio'])\n",
        "\n",
        "train['error_correction_factor'] = train['error_code'] / (train['panel_age'] + 1)\n",
        "test['error_correction_factor'] = test['error_code'] / (test['panel_age'] + 1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "train = train.drop(columns=['id'])\n",
        "test = test.drop(columns=['id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1748453962479
        }
      },
      "outputs": [],
      "source": [
        "# üéØ Target & Features\n",
        "new_df = pd.read_csv('train.csv')\n",
        "eff = new_df['efficiency']\n",
        "X = train\n",
        "y = eff\n",
        "X_test = test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns with infinity values in test:\n"
          ]
        }
      ],
      "source": [
        "# Check for infinity in test set as well\n",
        "inf_cols_test = X_test.columns[np.isinf(X_test).any()].tolist()\n",
        "\n",
        "print(\"Columns with infinity values in test:\")\n",
        "for col in inf_cols_test:\n",
        "    print(f\"- {col}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1748453964097
        }
      },
      "outputs": [],
      "source": [
        "# ‚öñÔ∏è Feature Scaling (optional with LGBM but improves stability)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1748453966939
        }
      },
      "outputs": [],
      "source": [
        "# üîÄ Train-validation split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'FINAL_STACK_test_predictions_stacked.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#combing results to get better predictions\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m tusk_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFINAL_STACK_test_predictions_stacked.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m aayu_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubmission_enriched_stackedv2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'FINAL_STACK_test_predictions_stacked.csv'"
          ]
        }
      ],
      "source": [
        "#combing results to get better predictions\n",
        "tusk_df = pd.read_csv('FINAL_STACK_test_predictions_stacked.csv')\n",
        "aayu_df = pd.read_csv('submission_enriched_stackedv2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Final RMSE: 0.1056\n",
            "‚úÖ R¬≤ Score: 0.4451\n",
            "üìå Top 10 Features Used: ['error_severity', 'temperature', 'module_temperature', 'temperature_squared', 'humidity', 'panel_health_index', 'maintenance_score', 'grid_stability', 'panel_age', 'soiling_ratio', 'log_irradiance', 'irradiance', 'irradiance_squared']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "import xgboost as xgb\n",
        "\n",
        "# 1. Prepare Data\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 2. Train a Base XGBoost to Get Feature Importance\n",
        "base_model = xgb.XGBRegressor(n_estimators=200, max_depth=4, learning_rate=0.05,\n",
        "                              subsample=0.8, colsample_bytree=0.8,\n",
        "                              reg_alpha=1.0, reg_lambda=1.0, n_jobs=-1, random_state=42)\n",
        "base_model.fit(X_train, y_train)\n",
        "\n",
        "# 3. Select Top 10 Features\n",
        "importances = base_model.feature_importances_\n",
        "top10_idx = np.argsort(importances)[-13:]\n",
        "top10_features = X.columns[top10_idx]\n",
        "\n",
        "X_train_sel = X_train[top10_features]\n",
        "X_val_sel = X_val[top10_features]\n",
        "\n",
        "# 4. Train Final Model with Top 10 Features\n",
        "xgb_final_model = xgb.XGBRegressor(n_estimators=300, max_depth=3, learning_rate=0.03,\n",
        "                                subsample=0.7, colsample_bytree=0.7,\n",
        "                                reg_alpha=0.5, reg_lambda=0.5, n_jobs=-1, random_state=42)\n",
        "xgb_final_model.fit(X_train_sel, y_train)\n",
        "\n",
        "# 5. Evaluate\n",
        "preds = xgb_final_model.predict(X_val_sel)\n",
        "rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
        "r2 = r2_score(y_val, preds)\n",
        "\n",
        "print(\"‚úÖ Final RMSE:\", round(rmse, 4))\n",
        "print(\"‚úÖ R¬≤ Score:\", round(r2, 4))\n",
        "print(\"üìå Top 10 Features Used:\", list(top10_features))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5184 candidates, totalling 25920 fits\n",
            "Best Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.03, 'max_depth': 3, 'n_estimators': 300, 'reg_alpha': 0.5, 'reg_lambda': 0.5, 'subsample': 0.7}\n",
            "Best RMSE: 0.10167348038030266\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300, 400],\n",
        "    'max_depth': [3, 4, 5, 6],\n",
        "    'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
        "    'subsample': [0.7, 0.8, 0.9],\n",
        "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
        "    'reg_alpha': [0, 0.5, 1.0],\n",
        "    'reg_lambda': [0, 0.5, 1.0]\n",
        "}\n",
        "\n",
        "# Initialize XGBoost model\n",
        "xgb_model = xgb.XGBRegressor(n_jobs=-1, random_state=42)\n",
        "\n",
        "# Grid Search\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid,\n",
        "                           cv=5, scoring='neg_root_mean_squared_error', \n",
        "                           verbose=1, n_jobs=-1)\n",
        "\n",
        "# Fit grid search\n",
        "grid_search.fit(X_train_sel, y_train)\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best RMSE:\", -grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ XGBoost submission file created: xgb_submission.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "test_id = pd.read_csv('test.csv')\n",
        "#xgb _final_preds = xgb_final_model.predict(test[top10_features])\n",
        "xgb_final_preds = xgb_final_model.predict(test[top10_features])\n",
        "# üìù Prepare XGBoost submissio\n",
        "\n",
        "# ‚úÖ Create submission file\n",
        "xgb_submission = pd.DataFrame({\n",
        "    'id': test_id['id'],\n",
        "    'efficiency': xgb_final_preds\n",
        "})\n",
        "xgb_submission.to_csv('xgb_submission.csv', index=False)\n",
        "print(\"‚úÖ XGBoost submission file created: xgb_submission.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# combined lgb and xgb predictions\n",
        "combined_preds = (tusk_df['efficiency']*0.4 + xgb_final_preds*0.6) \n",
        "# Create finl combined submission\n",
        "combined_submission = pd.DataFrame({\n",
        "    'id': test_id['id'],\n",
        "    'efficiency': combined_preds\n",
        "})\n",
        "combined_submission.to_csv('combined_submission_lgb_xgb_auto.csv', index=False) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Best performed model yet 89.90413"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Final combined submission file created: final_combined_submission_tusk_aayu_xgb.csv\n"
          ]
        }
      ],
      "source": [
        "# combined with xgb model and aayush model\n",
        "# combine xgb with aayush model\n",
        "aayu_df = pd.read_csv('submission_enriched_stackedv2.csv')\n",
        "combined_aayu_xgb = (aayu_df['efficiency']*0.4 + xgb_final_preds*0.6)\n",
        "# Create final combined submission with Aayu's model\n",
        "aayu_combined_submission = pd.DataFrame({\n",
        "    'id': test_id['id'],\n",
        "    'efficiency': combined_aayu_xgb\n",
        "})\n",
        "aayu_combined_submission.to_csv('aayu_combined_submission_xgb.csv', index=False)\n",
        "# Final combined submission with Tusk's model\n",
        "tusk_df = pd.read_csv('FINAL_STACK_test_predictions_stacked.csv')\n",
        "combined_tusk_aayu_xgb = (tusk_df['efficiency']*0.25 + aayu_combined_submission['efficiency']*0.25 + xgb_final_preds*0.5)\n",
        "# Create final combined submission with Tusk's model and Aayu's model\n",
        "final_combined_submission = pd.DataFrame({\n",
        "    'id': test_id['id'],\n",
        "    'efficiency': combined_tusk_aayu_xgb\n",
        "})\n",
        "final_combined_submission.to_csv('final_combined_submission_tusk_aayu_xgb.csv', index=False)\n",
        "# Final combined submission with Tusk's model and Aayu's model\n",
        "print(\"‚úÖ Final combined submission file created: final_combined_submission_tusk_aayu_xgb.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
